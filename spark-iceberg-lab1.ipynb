{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb4ab22-34f5-4a9b-a71b-3afc8e9654f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb998db-bf33-473b-b5ad-0bb9d55a8a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = (\n",
    "pyspark.SparkConf()\n",
    ".setAppName('spark-iceberg-lab1')\n",
    ".set('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.83.1,org.apache.hadoop:hadoop-aws:3.3.4')\n",
    ".set('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions')\n",
    ".set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    ".set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    ".set('spark.sql.catalog.nessie.uri', 'http://nessie:19120/api/v1')\n",
    ".set('spark.sql.catalog.nessie.ref', 'main')\n",
    ".set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    ".set('spark.sql.catalog.nessie.warehouse', 's3a://warehouse/')\n",
    ".set('spark.hadoop.fs.s3a.endpoint', 'http://minio:9000')\n",
    ".set('spark.hadoop.fs.s3a.access.key', 'admin')\n",
    ".set('spark.hadoop.fs.s3a.secret.key', 'password')\n",
    ".set('spark.hadoop.fs.s3a.path.style.access', 'true')\n",
    ".set('spark.hadoop.fs.s3a.connection.ssl.enabled', 'false')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c2d523-3ba9-45fb-987a-f51003555843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/docker/.local/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/docker/.ivy2/cache\n",
      "The jars for the packages stored in: /home/docker/.ivy2/jars\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-fa5ee98e-14f4-44c8-b56f-697a4e0d78c6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.2 in central\n",
      "\tfound org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.83.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 462ms :: artifacts dl 20ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.2 from central in [default]\n",
      "\torg.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.83.1 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-fa5ee98e-14f4-44c8-b56f-697a4e0d78c6\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/13ms)\n",
      "25/12/19 23:10:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c2e277e-ec30-46ff-bb6e-e0a409e2e4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|     demo|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases in nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89196262-a10e-4b07-8778-b4c0d3da9644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|     demo|      tbl|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in nessie.demo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5df2f972-3de6-4783-bfe2-71017d28a78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/19 23:35:24 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE nessie.demo.employee (\n",
    "id INT,\n",
    "role STRING,\n",
    "department STRING,\n",
    "salary FLOAT,\n",
    "region STRING)\n",
    "USING iceberg\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bbfe7bf-85f3-4c19-a7df-e007caefa37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|     demo|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases in nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bfa8d2f-578d-4577-91fd-acad2dffc2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|     demo| employee|      false|\n",
      "|     demo|      tbl|      false|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in nessie.demo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a5d6a48-3c71-44da-963c-20163056a718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE nessie.demo.emp_partitioned (\n",
    "id INT,\n",
    "role STRING,\n",
    "department STRING)\n",
    "USING iceberg\n",
    "PARTITIONED BY (department)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1569a459-44f6-4c90-ab8c-d66f52273cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+-----------+\n",
      "|namespace|      tableName|isTemporary|\n",
      "+---------+---------------+-----------+\n",
      "|     demo|emp_partitioned|      false|\n",
      "|     demo|       employee|      false|\n",
      "|     demo|            tbl|      false|\n",
      "+---------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in nessie.demo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecfffc70-e32f-4370-86e8-19e0916a14a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE TABLE nessie.demo.emp_partitioned_month (\n",
    "id INT,\n",
    "role STRING,\n",
    "department STRING,\n",
    "join_date DATE\n",
    ")\n",
    "USING iceberg\n",
    "PARTITIONED BY (months(join_date))\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43877587-3e27-471f-9779-75f29f755a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|     demo|     emp_partitioned|      false|\n",
      "|     demo|emp_partitioned_m...|      false|\n",
      "|     demo|            employee|      false|\n",
      "|     demo|                 tbl|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in nessie.demo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82ab8032-35fa-4dc5-9aea-221268936b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "ALTER TABLE nessie.demo.tbl RENAME TO tbl_renamed\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aabf203-0bc4-4343-b7d8-d377c8e71490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|     demo|     emp_partitioned|      false|\n",
      "|     demo|emp_partitioned_m...|      false|\n",
      "|     demo|            employee|      false|\n",
      "|     demo|         tbl_renamed|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in nessie.demo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "600b96f1-110e-4d8e-9a69-33107ffd23e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "ALTER TABLE nessie.demo.employee SET TBLPROPERTIES ('write.wap.enabled'='true')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b37c7270-1fd7-4b51-a6c0-56ffe64d898f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "ALTER TABLE nessie.demo.employee ADD COLUMN manager STRING\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "858a5771-3596-4f68-88b1-e2cbb86d6d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "ALTER TABLE nessie.demo.employee RENAME COLUMN role TO title\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "846aef93-f799-431e-b977-af232df6e71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[col_name: string, data_type: string, comment: string]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESC TABLE nessie.demo.employee\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2270888-5a7e-4feb-8356-72785dbaa921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|  col_name|data_type|comment|\n",
      "+----------+---------+-------+\n",
      "|        id|      int|   NULL|\n",
      "|     title|   string|   NULL|\n",
      "|department|   string|   NULL|\n",
      "|    salary|    float|   NULL|\n",
      "|    region|   string|   NULL|\n",
      "|   manager|   string|   NULL|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESC TABLE nessie.demo.employee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "532419c7-caba-477d-ae5a-e2968e74f859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|            col_name|           data_type|comment|\n",
      "+--------------------+--------------------+-------+\n",
      "|                  id|                 int|   NULL|\n",
      "|               title|              string|   NULL|\n",
      "|          department|              string|   NULL|\n",
      "|              salary|               float|   NULL|\n",
      "|              region|              string|   NULL|\n",
      "|             manager|              string|   NULL|\n",
      "|                    |                    |       |\n",
      "|  # Metadata Columns|                    |       |\n",
      "|            _spec_id|                 int|       |\n",
      "|          _partition|            struct<>|       |\n",
      "|               _file|              string|       |\n",
      "|                _pos|              bigint|       |\n",
      "|            _deleted|             boolean|       |\n",
      "|                    |                    |       |\n",
      "|# Detailed Table ...|                    |       |\n",
      "|                Name|nessie.demo.employee|       |\n",
      "|                Type|             MANAGED|       |\n",
      "|            Location|s3a://warehouse/d...|       |\n",
      "|            Provider|             iceberg|       |\n",
      "|               Owner|              docker|       |\n",
      "+--------------------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESC TABLE EXTENDED nessie.demo.employee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39034375-ed6a-4708-977f-851834de2823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                                                                                                                                                                                                                         |comment|\n",
      "+----------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|id                          |int                                                                                                                                                                                                                                                                               |NULL   |\n",
      "|title                       |string                                                                                                                                                                                                                                                                            |NULL   |\n",
      "|department                  |string                                                                                                                                                                                                                                                                            |NULL   |\n",
      "|salary                      |float                                                                                                                                                                                                                                                                             |NULL   |\n",
      "|region                      |string                                                                                                                                                                                                                                                                            |NULL   |\n",
      "|manager                     |string                                                                                                                                                                                                                                                                            |NULL   |\n",
      "|                            |                                                                                                                                                                                                                                                                                  |       |\n",
      "|# Metadata Columns          |                                                                                                                                                                                                                                                                                  |       |\n",
      "|_spec_id                    |int                                                                                                                                                                                                                                                                               |       |\n",
      "|_partition                  |struct<>                                                                                                                                                                                                                                                                          |       |\n",
      "|_file                       |string                                                                                                                                                                                                                                                                            |       |\n",
      "|_pos                        |bigint                                                                                                                                                                                                                                                                            |       |\n",
      "|_deleted                    |boolean                                                                                                                                                                                                                                                                           |       |\n",
      "|                            |                                                                                                                                                                                                                                                                                  |       |\n",
      "|# Detailed Table Information|                                                                                                                                                                                                                                                                                  |       |\n",
      "|Name                        |nessie.demo.employee                                                                                                                                                                                                                                                              |       |\n",
      "|Type                        |MANAGED                                                                                                                                                                                                                                                                           |       |\n",
      "|Location                    |s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26                                                                                                                                                                                                                |       |\n",
      "|Provider                    |iceberg                                                                                                                                                                                                                                                                           |       |\n",
      "|Owner                       |docker                                                                                                                                                                                                                                                                            |       |\n",
      "|Table Properties            |[current-snapshot-id=none,format=iceberg/parquet,format-version=2,gc.enabled=false,nessie.commit.id=457226fa50a6d9decabeb6120d72accc8b9be15bfc47dc26bf984d433ef4446f,write.metadata.delete-after-commit.enabled=false,write.parquet.compression-codec=zstd,write.wap.enabled=true]|       |\n",
      "+----------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESC TABLE EXTENDED nessie.demo.employee\n",
    "\"\"\").show(200, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78f93cf4-ffca-4c3d-bc55-f6bd813df99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                                                                                                                                                                                                  |comment|\n",
      "+----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|id                          |int                                                                                                                                                                                                                                                        |NULL   |\n",
      "|role                        |string                                                                                                                                                                                                                                                     |NULL   |\n",
      "|department                  |string                                                                                                                                                                                                                                                     |NULL   |\n",
      "|# Partition Information     |                                                                                                                                                                                                                                                           |       |\n",
      "|# col_name                  |data_type                                                                                                                                                                                                                                                  |comment|\n",
      "|department                  |string                                                                                                                                                                                                                                                     |NULL   |\n",
      "|                            |                                                                                                                                                                                                                                                           |       |\n",
      "|# Metadata Columns          |                                                                                                                                                                                                                                                           |       |\n",
      "|_spec_id                    |int                                                                                                                                                                                                                                                        |       |\n",
      "|_partition                  |struct<department:string>                                                                                                                                                                                                                                  |       |\n",
      "|_file                       |string                                                                                                                                                                                                                                                     |       |\n",
      "|_pos                        |bigint                                                                                                                                                                                                                                                     |       |\n",
      "|_deleted                    |boolean                                                                                                                                                                                                                                                    |       |\n",
      "|                            |                                                                                                                                                                                                                                                           |       |\n",
      "|# Detailed Table Information|                                                                                                                                                                                                                                                           |       |\n",
      "|Name                        |nessie.demo.emp_partitioned                                                                                                                                                                                                                                |       |\n",
      "|Type                        |MANAGED                                                                                                                                                                                                                                                    |       |\n",
      "|Location                    |s3a://warehouse/demo/emp_partitioned_df7d17c8-1352-46a3-92d8-c61e50467c3b                                                                                                                                                                                  |       |\n",
      "|Provider                    |iceberg                                                                                                                                                                                                                                                    |       |\n",
      "|Owner                       |docker                                                                                                                                                                                                                                                     |       |\n",
      "|Table Properties            |[current-snapshot-id=none,format=iceberg/parquet,format-version=2,gc.enabled=false,nessie.commit.id=457226fa50a6d9decabeb6120d72accc8b9be15bfc47dc26bf984d433ef4446f,write.metadata.delete-after-commit.enabled=false,write.parquet.compression-codec=zstd]|       |\n",
      "+----------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "DESC TABLE EXTENDED nessie.demo.emp_partitioned\n",
    "\"\"\").show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0b97b13-15ce-4480-bc99-859c0049cc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "ALTER TABLE nessie.demo.employee ADD PARTITION FIELD region\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29fbf3fa-e755-4711-935e-11c565e609d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "ALTER TABLE nessie.demo.employee WRITE ORDERED BY id ASC\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "337d192e-eaaa-481d-8722-db57f7f58cae",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Cannot add field id as an identifier field: not a required field",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43mALTER TABLE nessie.demo.employee SET IDENTIFIER FIELDS id\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: Cannot add field id as an identifier field: not a required field"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "ALTER TABLE nessie.demo.employee SET IDENTIFIER FIELDS id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9307206a-90af-456f-bf61-0daba96e4b06",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Cannot change nullable column to non-nullable: id.; line 2 pos 0;\nAlterColumn resolvedfieldname(StructField(id,IntegerType,true)), false\n+- ResolvedTable org.apache.iceberg.spark.SparkCatalog@5d4beb37, demo.employee, nessie.demo.employee, [id#442, title#443, department#444, salary#445, region#446, manager#447]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43mALTER TABLE nessie.demo.employee ALTER COLUMN id SET NOT NULL;\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[1;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[1;32m   1630\u001b[0m         )\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Cannot change nullable column to non-nullable: id.; line 2 pos 0;\nAlterColumn resolvedfieldname(StructField(id,IntegerType,true)), false\n+- ResolvedTable org.apache.iceberg.spark.SparkCatalog@5d4beb37, demo.employee, nessie.demo.employee, [id#442, title#443, department#444, salary#445, region#446, manager#447]\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "ALTER TABLE nessie.demo.employee ALTER COLUMN id SET NOT NULL;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8b0efaa-5774-4406-9805-9980a613bd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE nessie.demo.tbl_renamed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db8a462b-58df-4349-b88c-55f5218174d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|     demo|     emp_partitioned|      false|\n",
      "|     demo|emp_partitioned_m...|      false|\n",
      "|     demo|            employee|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in nessie.demo\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e157288-3243-40c4-b1ee-ba2d170054af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+------+------+-------+\n",
      "| id|title|department|salary|region|manager|\n",
      "+---+-----+----------+------+------+-------+\n",
      "+---+-----+----------+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nessie.demo.employee\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3019938f-dcd8-424d-b8cd-f84988ad5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emp = spark.table(\"nessie.demo.employee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "091560be-048f-42a1-bd31-15aca1e87470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+------+------+-------+\n",
      "| id|title|department|salary|region|manager|\n",
      "+---+-----+----------+------+------+-------+\n",
      "+---+-----+----------+------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12af5ae1-9d03-4203-a746-ddcf4d1d685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "676ce750-8fa9-44a6-bd44-535df7c0202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+\n",
      "|namespace|           tableName|isTemporary|\n",
      "+---------+--------------------+-----------+\n",
      "|     demo|     emp_partitioned|      false|\n",
      "|     demo|emp_partitioned_m...|      false|\n",
      "|     demo|            employee|      false|\n",
      "+---------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables in nessie\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d126fb82-237e-4ce4-ab71-dc39909905ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "INSERT INTO nessie.demo.employee \n",
    "VALUES \n",
    "(1, 'Software Engineer', 'Engineering', 25000, 'NA', 'Jack'), \n",
    "(2, 'Director', 'Sales', 22000, 'EMEA', 'Bo W')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73bdcdf0-adc8-4c2b-be8a-4bc9f22e7392",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+-----------+-------+------+-------+\n",
      "| id|            title| department| salary|region|manager|\n",
      "+---+-----------------+-----------+-------+------+-------+\n",
      "|  2|         Director|      Sales|22000.0|  EMEA|   Bo W|\n",
      "|  1|Software Engineer|Engineering|25000.0|    NA|   Jack|\n",
      "+---+-----------------+-----------+-------+------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select * from nessie.demo.employee\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33eb3302-2629-430d-a97d-8bd700454c31",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Failed to find data source: avro. Avro is built-in but external data source module since Spark 2.4. Please deploy the application as per the deployment section of Apache Avro Data Source Guide.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the Avro manifest list\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mavro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ms3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/snap-4776718034125825857-1-a461d5ed-9ebd-4a76-88ef-83515d85d8a9.avro\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Show it as a table (easy reading)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py:307\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Failed to find data source: avro. Avro is built-in but external data source module since Spark 2.4. Please deploy the application as per the deployment section of Apache Avro Data Source Guide."
     ]
    }
   ],
   "source": [
    "# Read the Avro manifest list\n",
    "df = spark.read.format(\"avro\").load(\"s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/snap-4776718034125825857-1-a461d5ed-9ebd-4a76-88ef-83515d85d8a9.avro\")\n",
    "\n",
    "# Show it as a table (easy reading)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7dbb7cf7-a786-4e9f-a539-16c6b12a2baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+---------+---------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|committed_at           |snapshot_id        |parent_id|operation|manifest_list                                                                                                                                   |summary                                                                                                                                                                                                                                                                                         |\n",
      "+-----------------------+-------------------+---------+---------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|2025-12-22 22:37:16.707|4776718034125825857|NULL     |append   |s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/snap-4776718034125825857-1-a461d5ed-9ebd-4a76-88ef-83515d85d8a9.avro|{spark.app.id -> local-1766185832127, added-data-files -> 2, added-records -> 2, added-files-size -> 3284, changed-partition-count -> 2, total-records -> 2, total-files-size -> 3284, total-data-files -> 2, total-delete-files -> 0, total-position-deletes -> 0, total-equality-deletes -> 0}|\n",
      "+-----------------------+-------------------+---------+---------+------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM nessie.demo.employee.snapshots\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e14ee1b-b877-4da1-87f1-757077ba03e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+--------------------------+\n",
      "|content|path                                                                                                                    |length|partition_spec_id|added_snapshot_id  |added_data_files_count|existing_data_files_count|deleted_data_files_count|added_delete_files_count|existing_delete_files_count|deleted_delete_files_count|partition_summaries       |\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+--------------------------+\n",
      "|0      |s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/a461d5ed-9ebd-4a76-88ef-83515d85d8a9-m0.avro|7286  |1                |4776718034125825857|2                     |0                        |0                       |0                       |0                          |0                         |[{false, false, EMEA, NA}]|\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------+------+-----------------+-------------------+----------------------+-------------------------+------------------------+------------------------+---------------------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM nessie.demo.employee.manifests\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ddf75f71-66ff-41f9-8064-9de73a74e243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+------------------------------------------------------------------------------------------------------------------------------------+-------------------+----------------+----------------------+\n",
      "|timestamp              |file                                                                                                                                |latest_snapshot_id |latest_schema_id|latest_sequence_number|\n",
      "+-----------------------+------------------------------------------------------------------------------------------------------------------------------------+-------------------+----------------+----------------------+\n",
      "|2025-12-20 19:06:28.317|s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/00000-d636e9e1-f73b-4c55-9712-132f8c4e7d8d.metadata.json|NULL               |NULL            |NULL                  |\n",
      "|2025-12-20 19:26:43.429|s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/00001-3efbdb2d-34de-4d27-a519-88e7caa35c28.metadata.json|NULL               |NULL            |NULL                  |\n",
      "|2025-12-20 19:40:04.117|s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/00002-e3fe2283-2188-4be2-8089-cab70adfeaf6.metadata.json|NULL               |NULL            |NULL                  |\n",
      "|2025-12-20 22:20:11.146|s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/00003-7dbc3a2a-e016-4eb8-a603-8b08931b095d.metadata.json|NULL               |NULL            |NULL                  |\n",
      "|2025-12-20 23:21:13.028|s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/00004-35493455-9cfb-40d8-8901-c817e457d203.metadata.json|NULL               |NULL            |NULL                  |\n",
      "|2025-12-22 22:37:08.655|s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/00005-b7e15f88-0f8e-4469-a60c-6b13bc56008d.metadata.json|NULL               |NULL            |NULL                  |\n",
      "|2025-12-23 05:02:09.963|s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/00006-6f7f0bbf-6f64-46ec-8460-b8608b1ec724.metadata.json|4776718034125825857|2               |1                     |\n",
      "+-----------------------+------------------------------------------------------------------------------------------------------------------------------------+-------------------+----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM nessie.demo.employee.metadata_log_entries\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b6bf8f3-71fb-4d0a-abb5-5b5d9358e1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------------+-----------+-------+---------+------------+------------------+------------------------------------------------------+------------------------------------------------+------------------------------------------------+----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------------+------------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|content|file_path                                                                                                                                       |file_format|spec_id|partition|record_count|file_size_in_bytes|column_sizes                                          |value_counts                                    |null_value_counts                               |nan_value_counts|lower_bounds                                                                                                                                                               |upper_bounds                                                                                                                                                               |key_metadata|split_offsets|equality_ids|sort_order_id|readable_metrics                                                                                                                                                                                                   |\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------------+-----------+-------+---------+------------+------------------+------------------------------------------------------+------------------------------------------------+------------------------------------------------+----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------------+------------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0      |s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/data/region=EMEA/00000-4-084c8cb7-a79e-4234-8d10-978a45faf592-0-00001.parquet|PARQUET    |1      |{EMEA}   |1           |1597              |{1 -> 36, 2 -> 44, 3 -> 41, 4 -> 36, 5 -> 40, 6 -> 40}|{1 -> 1, 2 -> 1, 3 -> 1, 4 -> 1, 5 -> 1, 6 -> 1}|{1 -> 0, 2 -> 0, 3 -> 0, 4 -> 0, 5 -> 0, 6 -> 0}|{4 -> 0}        |{1 -> [02 00 00 00], 2 -> [44 69 72 65 63 74 6F 72], 3 -> [53 61 6C 65 73], 4 -> [00 E0 AB 46], 5 -> [45 4D 45 41], 6 -> [42 6F 20 57]}                                    |{1 -> [02 00 00 00], 2 -> [44 69 72 65 63 74 6F 72], 3 -> [53 61 6C 65 73], 4 -> [00 E0 AB 46], 5 -> [45 4D 45 41], 6 -> [42 6F 20 57]}                                    |NULL        |[4]          |NULL        |0            |{{41, 1, 0, NULL, Sales, Sales}, {36, 1, 0, NULL, 2, 2}, {40, 1, 0, NULL, Bo W, Bo W}, {40, 1, 0, NULL, EMEA, EMEA}, {36, 1, 0, 0, 22000.0, 22000.0}, {44, 1, 0, NULL, Director, Director}}                        |\n",
      "|0      |s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/data/region=NA/00000-4-084c8cb7-a79e-4234-8d10-978a45faf592-0-00002.parquet  |PARQUET    |1      |{NA}     |1           |1687              |{1 -> 36, 2 -> 53, 3 -> 47, 4 -> 35, 5 -> 38, 6 -> 40}|{1 -> 1, 2 -> 1, 3 -> 1, 4 -> 1, 5 -> 1, 6 -> 1}|{1 -> 0, 2 -> 0, 3 -> 0, 4 -> 0, 5 -> 0, 6 -> 0}|{4 -> 0}        |{1 -> [01 00 00 00], 2 -> [53 6F 66 74 77 61 72 65 20 45 6E 67 69 6E 65 65], 3 -> [45 6E 67 69 6E 65 65 72 69 6E 67], 4 -> [00 50 C3 46], 5 -> [4E 41], 6 -> [4A 61 63 6B]}|{1 -> [01 00 00 00], 2 -> [53 6F 66 74 77 61 72 65 20 45 6E 67 69 6E 65 66], 3 -> [45 6E 67 69 6E 65 65 72 69 6E 67], 4 -> [00 50 C3 46], 5 -> [4E 41], 6 -> [4A 61 63 6B]}|NULL        |[4]          |NULL        |0            |{{47, 1, 0, NULL, Engineering, Engineering}, {36, 1, 0, NULL, 1, 1}, {40, 1, 0, NULL, Jack, Jack}, {38, 1, 0, NULL, NA, NA}, {35, 1, 0, 0, 25000.0, 25000.0}, {53, 1, 0, NULL, Software Enginee, Software Enginef}}|\n",
      "+-------+------------------------------------------------------------------------------------------------------------------------------------------------+-----------+-------+---------+------------+------------------+------------------------------------------------------+------------------------------------------------+------------------------------------------------+----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-------------+------------+-------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM nessie.demo.employee.files\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ace7b980-ea95-47e4-998c-9653ca1d3cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- current-schema-id: long (nullable = true)\n",
      " |-- current-snapshot-id: long (nullable = true)\n",
      " |-- default-sort-order-id: long (nullable = true)\n",
      " |-- default-spec-id: long (nullable = true)\n",
      " |-- format-version: long (nullable = true)\n",
      " |-- last-column-id: long (nullable = true)\n",
      " |-- last-partition-id: long (nullable = true)\n",
      " |-- last-sequence-number: long (nullable = true)\n",
      " |-- last-updated-ms: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- metadata-log: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- metadata-file: string (nullable = true)\n",
      " |    |    |-- timestamp-ms: long (nullable = true)\n",
      " |-- partition-specs: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- fields: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- field-id: long (nullable = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- source-id: long (nullable = true)\n",
      " |    |    |    |    |-- transform: string (nullable = true)\n",
      " |    |    |-- spec-id: long (nullable = true)\n",
      " |-- partition-statistics: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- properties: struct (nullable = true)\n",
      " |    |-- gc.enabled: string (nullable = true)\n",
      " |    |-- nessie.commit.id: string (nullable = true)\n",
      " |    |-- owner: string (nullable = true)\n",
      " |    |-- write.distribution-mode: string (nullable = true)\n",
      " |    |-- write.metadata.delete-after-commit.enabled: string (nullable = true)\n",
      " |    |-- write.parquet.compression-codec: string (nullable = true)\n",
      " |    |-- write.wap.enabled: string (nullable = true)\n",
      " |-- refs: struct (nullable = true)\n",
      " |    |-- main: struct (nullable = true)\n",
      " |    |    |-- snapshot-id: long (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- schemas: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- fields: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- required: boolean (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- schema-id: long (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- snapshot-log: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- snapshot-id: long (nullable = true)\n",
      " |    |    |-- timestamp-ms: long (nullable = true)\n",
      " |-- snapshots: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- manifest-list: string (nullable = true)\n",
      " |    |    |-- schema-id: long (nullable = true)\n",
      " |    |    |-- sequence-number: long (nullable = true)\n",
      " |    |    |-- snapshot-id: long (nullable = true)\n",
      " |    |    |-- summary: struct (nullable = true)\n",
      " |    |    |    |-- added-data-files: string (nullable = true)\n",
      " |    |    |    |-- added-files-size: string (nullable = true)\n",
      " |    |    |    |-- added-records: string (nullable = true)\n",
      " |    |    |    |-- changed-partition-count: string (nullable = true)\n",
      " |    |    |    |-- operation: string (nullable = true)\n",
      " |    |    |    |-- spark.app.id: string (nullable = true)\n",
      " |    |    |    |-- total-data-files: string (nullable = true)\n",
      " |    |    |    |-- total-delete-files: string (nullable = true)\n",
      " |    |    |    |-- total-equality-deletes: string (nullable = true)\n",
      " |    |    |    |-- total-files-size: string (nullable = true)\n",
      " |    |    |    |-- total-position-deletes: string (nullable = true)\n",
      " |    |    |    |-- total-records: string (nullable = true)\n",
      " |    |    |-- timestamp-ms: long (nullable = true)\n",
      " |-- sort-orders: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- fields: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- direction: string (nullable = true)\n",
      " |    |    |    |    |-- null-order: string (nullable = true)\n",
      " |    |    |    |    |-- source-id: long (nullable = true)\n",
      " |    |    |    |    |-- transform: string (nullable = true)\n",
      " |    |    |-- order-id: long (nullable = true)\n",
      " |-- statistics: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- table-uuid: string (nullable = true)\n",
      "\n",
      "+-----------------+-------------------+---------------------+---------------+--------------+--------------+-----------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|current-schema-id|current-snapshot-id|default-sort-order-id|default-spec-id|format-version|last-column-id|last-partition-id|last-sequence-number|last-updated-ms|            location|        metadata-log|     partition-specs|partition-statistics|          properties|                refs|             schemas|        snapshot-log|           snapshots|         sort-orders|statistics|          table-uuid|\n",
      "+-----------------+-------------------+---------------------+---------------+--------------+--------------+-----------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "|                2|4776718034125825857|                    1|              1|             2|             6|             1000|                   1|  1766443036707|s3a://warehouse/d...|[{s3a://warehouse...|[{[], 0}, {[{1000...|                  []|{false, 001d1df2c...|{{477671803412582...|[{[{1, id, false,...|[{477671803412582...|[{s3a://warehouse...|[{[], 0}, {[{asc,...|        []|28ff71a9-89bc-4ab...|\n",
      "+-----------------+-------------------+---------------------+---------------+--------------+--------------+-----------------+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the metadata file from your MinIO/S3 path\n",
    "df = spark.read.option(\"multiLine\", True).json(\"s3a://warehouse/demo/employee_f1ae59e9-eab2-4bba-bf4a-1b2fff895d26/metadata/00006-6f7f0bbf-6f64-46ec-8460-b8608b1ec724.metadata.json\")\n",
    "\n",
    "# View the structure\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852161ca-debb-47e8-b855-0ce7935906bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
